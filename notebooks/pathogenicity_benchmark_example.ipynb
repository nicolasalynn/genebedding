{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pathogenicity Prediction Benchmark\n",
    "\n",
    "This notebook demonstrates how to use the pathogenicity prediction benchmark to compare masked nucleotide prediction across different genomic foundation models.\n",
    "\n",
    "The benchmark evaluates how well models can distinguish pathogenic from benign variants based on their raw nucleotide predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from genebeddings.benchmarks.pathogenicity_predictions import PathogenicityBenchmark\n",
    "\n",
    "# Import model wrappers that support masked nucleotide prediction\n",
    "from genebeddings.wrappers.nt_wrapper import NTWrapper\n",
    "from genebeddings.wrappers.caduceus_wrapper import CaduceusWrapper\n",
    "from genebeddings.wrappers.specieslm_wrapper import SpeciesLMWrapper\n",
    "from genebeddings.wrappers.convnova_wrapper import ConvNOVAWrapper\n",
    "from genebeddings.wrappers.rinalmo_wrapper import RiNALMoWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Benchmark\n",
    "\n",
    "Provide the path to your ClinVar CSV file. The CSV should contain:\n",
    "- `chrom`: Chromosome (e.g., 'chr1', '1')\n",
    "- `pos`: Genomic position (1-based)\n",
    "- `ref`: Reference allele (single nucleotide)\n",
    "- `alt`: Alternate allele (single nucleotide)\n",
    "- `clinical_significance`: Pathogenic/Benign classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to ClinVar CSV\n",
    "CLINVAR_CSV = \"path/to/clinvar.csv\"\n",
    "\n",
    "# Initialize benchmark\n",
    "benchmark = PathogenicityBenchmark(\n",
    "    clinvar_csv_path=CLINVAR_CSV,\n",
    "    fasta_reference=\"hg38\",\n",
    "    context_size=512  # bases on each side of variant\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Models to Compare\n",
    "\n",
    "Add the models you want to benchmark. Each model must support masked nucleotide prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Nucleotide Transformer\n",
    "print(\"Loading Nucleotide Transformer...\")\n",
    "nt_wrapper = NTWrapper(\n",
    "    model_id=\"InstaDeepAI/nucleotide-transformer-v2-500m-multi-species\"\n",
    ")\n",
    "benchmark.add_model(\"nt\", nt_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Caduceus\n",
    "print(\"Loading Caduceus...\")\n",
    "caduceus_wrapper = CaduceusWrapper(\n",
    "    model_id=\"kuleshov-group/caduceus-ph_seqlen-131k_d_model-256_n_layer-16\"\n",
    ")\n",
    "benchmark.add_model(\"caduceus\", caduceus_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Add more models\n",
    "# benchmark.add_model(\"specieslm\", SpeciesLMWrapper())\n",
    "# benchmark.add_model(\"convnova\", ConvNOVAWrapper())\n",
    "# benchmark.add_model(\"rinalmo\", RiNALMoWrapper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Benchmark\n",
    "\n",
    "Run the benchmark on all variants. Use `max_variants` to test on a subset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on a small subset first for testing\n",
    "results_df = benchmark.run_benchmark(\n",
    "    max_variants=100,      # Set to None to use all variants\n",
    "    balance_classes=True   # Balance pathogenic and benign variants\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first few results\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics\n",
    "analysis = benchmark.analyze_results(results_df)\n",
    "benchmark.print_summary(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probability ratio distributions for each model\n",
    "model_names = [col.replace('_prob_ratio', '') for col in results_df.columns if col.endswith('_prob_ratio')]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(model_names), figsize=(6*len(model_names), 5))\n",
    "if len(model_names) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, model_name in zip(axes, model_names):\n",
    "    ratio_col = f'{model_name}_prob_ratio'\n",
    "    \n",
    "    # Split by pathogenic vs benign\n",
    "    pathogenic = results_df[results_df['label'] == 'pathogenic'][ratio_col].dropna()\n",
    "    benign = results_df[results_df['label'] == 'benign'][ratio_col].dropna()\n",
    "    \n",
    "    # Plot distributions\n",
    "    ax.hist(pathogenic, bins=30, alpha=0.5, label='Pathogenic', color='red', density=True)\n",
    "    ax.hist(benign, bins=30, alpha=0.5, label='Benign', color='blue', density=True)\n",
    "    \n",
    "    ax.axvline(1.0, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Ratio = 1')\n",
    "    ax.set_xlabel('Alt Prob / Ref Prob')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'{model_name.upper()}\\nProbability Ratios')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models side-by-side\n",
    "comparison_data = []\n",
    "for model_name in model_names:\n",
    "    ratio_col = f'{model_name}_prob_ratio'\n",
    "    \n",
    "    for label in ['pathogenic', 'benign']:\n",
    "        ratios = results_df[results_df['label'] == label][ratio_col].dropna()\n",
    "        for ratio in ratios:\n",
    "            comparison_data.append({\n",
    "                'model': model_name,\n",
    "                'label': label,\n",
    "                'prob_ratio': ratio\n",
    "            })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=comparison_df, x='model', y='prob_ratio', hue='label')\n",
    "plt.axhline(1.0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "plt.ylabel('Alt Prob / Ref Prob')\n",
    "plt.xlabel('Model')\n",
    "plt.title('Pathogenic vs Benign: Probability Ratios Across Models')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend(title='Variant Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Consensus Analysis\n",
    "\n",
    "Check how often models agree on predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each variant, check if models predict alt_prob < ref_prob (deleterious)\n",
    "if len(model_names) > 1:\n",
    "    for model_name in model_names:\n",
    "        results_df[f'{model_name}_predicts_deleterious'] = (\n",
    "            results_df[f'{model_name}_prob_ratio'] < 1.0\n",
    "        )\n",
    "    \n",
    "    # Count agreements\n",
    "    deleterious_cols = [f'{m}_predicts_deleterious' for m in model_names]\n",
    "    results_df['n_models_agree_deleterious'] = results_df[deleterious_cols].sum(axis=1)\n",
    "    \n",
    "    # Show consensus\n",
    "    print(\"\\nModel Consensus:\")\n",
    "    print(\"=\"*50)\n",
    "    consensus_summary = results_df.groupby(['label', 'n_models_agree_deleterious']).size().unstack(fill_value=0)\n",
    "    print(consensus_summary)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    for ax, label in zip(axes, ['pathogenic', 'benign']):\n",
    "        subset = results_df[results_df['label'] == label]\n",
    "        counts = subset['n_models_agree_deleterious'].value_counts().sort_index()\n",
    "        \n",
    "        ax.bar(counts.index, counts.values, color='red' if label == 'pathogenic' else 'blue', alpha=0.6)\n",
    "        ax.set_xlabel('Number of Models Predicting Deleterious')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title(f'{label.capitalize()} Variants')\n",
    "        ax.set_xticks(range(len(model_names) + 1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results\n",
    "results_df.to_csv(\"pathogenicity_benchmark_results.csv\", index=False)\n",
    "print(\"Results saved to: pathogenicity_benchmark_results.csv\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_rows = []\n",
    "for model_name, stats in analysis.items():\n",
    "    summary_rows.append({\n",
    "        'model': model_name,\n",
    "        'pathogenic_mean_ref_prob': stats['pathogenic']['mean_ref_prob'],\n",
    "        'pathogenic_mean_alt_prob': stats['pathogenic']['mean_alt_prob'],\n",
    "        'pathogenic_mean_prob_ratio': stats['pathogenic']['mean_prob_ratio'],\n",
    "        'benign_mean_ref_prob': stats['benign']['mean_ref_prob'],\n",
    "        'benign_mean_alt_prob': stats['benign']['mean_alt_prob'],\n",
    "        'benign_mean_prob_ratio': stats['benign']['mean_prob_ratio'],\n",
    "        'cohens_d': stats.get('cohens_d', np.nan)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(\"pathogenicity_benchmark_summary.csv\", index=False)\n",
    "print(\"Summary saved to: pathogenicity_benchmark_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "**Expected patterns:**\n",
    "- **Pathogenic variants**: Models should assign lower probability to the alternate allele compared to the reference (prob_ratio < 1.0), indicating the mutation is deleterious\n",
    "- **Benign variants**: Models should assign similar or higher probability to the alternate allele (prob_ratio >= 1.0), indicating the mutation is neutral or beneficial\n",
    "\n",
    "**Metrics:**\n",
    "- **Cohen's d**: Measures how well the model discriminates between pathogenic and benign. Positive values indicate better discrimination.\n",
    "- **Probability ratio**: alt_prob / ref_prob. Values < 1 suggest deleterious, values >= 1 suggest neutral/beneficial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
