{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OKGP epistasis: pull double variants from 1000 Genomes\n",
    "\n",
    "Build a clean set of **double-variant (epistasis) IDs** from the 1000 Genomes Project (OKGP) for use in embedding and epistasis analyses.\n",
    "\n",
    "**Pipeline:**\n",
    "1. **Load or generate** 1000 Genomes chr12 double variants (pairs within a max distance, e.g. 100 bp).\n",
    "   - Either load a pre-built CSV (`g1k_chr12_double_variants_max100bp.csv`) or run the VCF scan (optional, slow).\n",
    "2. **Annotate** each pair with gene and strand (GENCODE) using the first variant's position.\n",
    "3. **Build** `mut1`, `mut2`, and `epistasis_id` in the same format as other datasets (e.g. KRAS/FAS/MST1R).\n",
    "4. **Save** to `okgp_epistasis.csv` (or `okgp_doubles_subset.csv`).\n",
    "\n",
    "**Data sources:**\n",
    "- 1000 Genomes high-coverage VCF (e.g. `20201028_CCDG_14151_B01_GRM_WGS_2020-08-05_chr12.recalibrated_variants.vcf.gz`).\n",
    "- The same logic is used in `tcga_double_variants.ipynb` to produce `g1k_chr12_double_variants_max100bp.csv`; downstream `get_data.ipynb` and `running_okgp_doubles.ipynb` consume that CSV after adding gene/mut_id/epistasis_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Ensure repo root is on path so \"notebooks\" can be imported\n",
    "ROOT = Path.cwd()\n",
    "for _ in range(4):\n",
    "    if (ROOT / \"notebooks\" / \"paper_data_config.py\").exists():\n",
    "        break\n",
    "    ROOT = ROOT.parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "# Paths (set for your environment)\n",
    "GENE_STRAND_PATH = \"/tamir2/nicolaslynn/projects/dlm_wrappers/genebeddings/assets/benchmarks/gene_strands.csv\"\n",
    "GTF_PATH = \"/tamir2/nicolaslynn/data/GENCODE/raw/gencode.v49.annotation.gtf.gz\"\n",
    "\n",
    "# Input: pre-built 1000G chr12 double variants (from tcga_double_variants.ipynb)\n",
    "G1K_CHR12_CSV = \"g1k_chr12_double_variants_max100bp.csv\"\n",
    "g1k_path = \"/tamir2/nicolaslynn/projects/genomenet/genomenet/notebooks/data_generation_final/g1k_chr12_double_variants_max100bp.csv\"\n",
    "\n",
    "# Output under paper data root\n",
    "from notebooks.paper_data_config import data_dir\n",
    "OUT_OKGP_EPISTASIS = data_dir() / \"okgp_epistasis.csv\"\n",
    "\n",
    "# Sampling: weight by theoretical distance distribution (n(d) = L - d for window length L)\n",
    "SAMPLE_SIZE = 100_000   # total pairs to keep (or None to skip sampling)\n",
    "L = 100                 # window length (match your double-variant window)\n",
    "max_d = 100             # max distance (or your MAX_DISTANCE_BP)\n",
    "\n",
    "def theoretical_weight(d):\n",
    "    \"\"\"Theoretical count for each d in \"all pairs in window L\": n(d) = L - d for d in 1..L-1.\"\"\"\n",
    "    if d < 1 or d >= L:\n",
    "        return 0.0\n",
    "    return float(L - d)\n",
    "\n",
    "# Optional: filter by distance (bp). Set to None to keep all.\n",
    "MAX_DISTANCE_BP = None  # e.g. 5 for adjacent only\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENE_STRAND = pd.read_csv(GENE_STRAND_PATH).set_index(\"gene_name\").Strand.to_dict()\n",
    "\n",
    "def make_mut_id(row, pos_col=\"pos\", ref_col=\"ref\", var_col=\"alt\", chrom_col=\"chrom\", gene_col=\"gene\", rev_col=None):\n",
    "    if rev_col is None:\n",
    "        rev = GENE_STRAND.get(row[gene_col], False)\n",
    "    else:\n",
    "        rev = row[rev_col]\n",
    "    s = \"N\" if rev else \"P\"\n",
    "    chrom = str(row[chrom_col]).strip(\"chr\")\n",
    "    return f\"{row[gene_col]}:{chrom}:{int(row[pos_col])}:{row[ref_col]}:{row[var_col]}:{s}\"\n",
    "\n",
    "import pyranges as pr\n",
    "genes_gr = pr.read_gtf(GTF_PATH)\n",
    "genes = genes_gr[genes_gr.Feature == \"gene\"]\n",
    "\n",
    "def annotate_gene_names(row):\n",
    "    chrom = getattr(row, \"chrom\", row.get(\"Chromosome\", \"12\"))\n",
    "    chrom = str(chrom).strip(\"chr\")\n",
    "    if not chrom.startswith(\"chr\"):\n",
    "        chrom = f\"chr{chrom}\"\n",
    "    pos = int(getattr(row, \"pos1\", row.get(\"pos1\")))\n",
    "    query = pr.PyRanges(chromosomes=[chrom], starts=[pos], ends=[pos + 1])\n",
    "    hits = genes.join(query)\n",
    "    if hits.df.empty:\n",
    "        return pd.Series({\"gene\": np.nan, \"rev\": np.nan})\n",
    "    df = hits.df\n",
    "    df = df[df[\"gene_type\"] == \"protein_coding\"]\n",
    "    if df.empty:\n",
    "        return pd.Series({\"gene\": np.nan, \"rev\": np.nan})\n",
    "    is_plus = df[\"Strand\"] == \"+\"\n",
    "    df = df.copy()\n",
    "    df[\"tss\"] = np.where(is_plus, df[\"Start\"], df[\"End\"])\n",
    "    df[\"dist_to_tss\"] = (df[\"tss\"] - pos).abs()\n",
    "    best = df.loc[df[\"dist_to_tss\"].idxmin()]\n",
    "    rev = best[\"Strand\"] == \"-\"\n",
    "    return pd.Series({\"gene\": best[\"gene_name\"], \"rev\": rev})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load 1000 Genomes chr12 double variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve path: use g1k_path if file exists, else try G1K_CHR12_CSV relative paths\n",
    "import os\n",
    "if not os.path.isfile(g1k_path):\n",
    "    for candidate in [G1K_CHR12_CSV, os.path.join(\"..\", G1K_CHR12_CSV)]:\n",
    "        if os.path.isfile(candidate):\n",
    "            g1k_path = candidate\n",
    "            break\n",
    "\n",
    "okgp = pd.read_csv(g1k_path)\n",
    "okgp = okgp.rename(columns={\"distance_bp\": \"distance\", \"Chromosome\": \"chrom\"})\n",
    "if \"chrom\" not in okgp.columns:\n",
    "    okgp[\"chrom\"] = okgp.get(\"Chromosome\", \"chr12\")\n",
    "okgp[\"chrom\"] = okgp[\"chrom\"].astype(str).str.strip(\"chr\")\n",
    "\n",
    "if MAX_DISTANCE_BP is not None:\n",
    "    okgp = okgp[okgp[\"distance\"] <= MAX_DISTANCE_BP]\n",
    "\n",
    "# Sample with theoretical distance distribution (L - d) so distance distribution matches \"all pairs in window\"\n",
    "if SAMPLE_SIZE is not None and len(okgp) > SAMPLE_SIZE:\n",
    "    okgp[\"weight\"] = okgp[\"distance\"].clip(lower=1).apply(theoretical_weight)\n",
    "    okgp = okgp[okgp[\"weight\"] > 0]\n",
    "    weights = okgp[\"weight\"] / okgp[\"weight\"].sum()\n",
    "    okgp = okgp.sample(n=SAMPLE_SIZE, weights=weights, random_state=42, replace=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(okgp)} pairs from {g1k_path}\")\n",
    "okgp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Annotate gene and strand, build mut1 / mut2 / epistasis_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okgp[[\"gene\", \"rev\"]] = okgp.progress_apply(annotate_gene_names, axis=1)\n",
    "okgp[\"gene\"] = okgp[\"gene\"].fillna(\"GENE\")\n",
    "\n",
    "okgp[\"mut1\"] = okgp.progress_apply(\n",
    "    lambda r: make_mut_id(r, pos_col=\"pos1\", ref_col=\"ref1\", var_col=\"alt1\", chrom_col=\"chrom\", gene_col=\"gene\", rev_col=\"rev\"),\n",
    "    axis=1,\n",
    ")\n",
    "okgp[\"mut2\"] = okgp.progress_apply(\n",
    "    lambda r: make_mut_id(r, pos_col=\"pos2\", ref_col=\"ref2\", var_col=\"alt2\", chrom_col=\"chrom\", gene_col=\"gene\", rev_col=\"rev\"),\n",
    "    axis=1,\n",
    ")\n",
    "okgp[\"epistasis_id\"] = okgp[\"mut1\"] + \"|\" + okgp[\"mut2\"]\n",
    "\n",
    "print(okgp[[\"epistasis_id\", \"gene\", \"distance\", \"AF1\", \"AF2\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = OUT_OKGP_EPISTASIS  # saved in current working directory\n",
    "okgp.to_csv(out_path, index=False)\n",
    "print(f\"Saved {len(okgp)} rows to {out_path}\")\n",
    "okgp[[\"epistasis_id\", \"gene\", \"distance\", \"AF1\", \"AF2\", \"mut1\", \"mut2\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Optional: Build g1k chr12 double variants from VCF\n",
    "\n",
    "If you do not have `g1k_chr12_double_variants_max100bp.csv`, you can generate it from the 1000 Genomes VCF. Requires `pysam` and a local index (`.tbi`) for the chr12 VCF. This step is slow (~1â€“2 hours for chr12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and set paths to run.\n",
    "# import pysam\n",
    "#\n",
    "# VCF_URL = (\n",
    "#     \"https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/\"\n",
    "#     \"1000G_2504_high_coverage/working/20201028_3202_raw_GT_with_annot/\"\n",
    "#     \"20201028_CCDG_14151_B01_GRM_WGS_2020-08-05_chr12.recalibrated_variants.vcf.gz\"\n",
    "# )\n",
    "# LOCAL_TBI = \"/path/to/20201028_CCDG_14151_B01_GRM_WGS_2020-08-05_chr12.recalibrated_variants.vcf.gz.tbi\"\n",
    "# CONTIG, MAX_DIST = \"chr12\", 100\n",
    "#\n",
    "# def is_biallelic_snv(rec):\n",
    "#     if rec.alts is None or len(rec.alts) != 1: return False\n",
    "#     return len(rec.ref) == 1 and len(rec.alts[0]) == 1\n",
    "# def is_pass(rec):\n",
    "#     f = set(rec.filter.keys())\n",
    "#     return not f or \"PASS\" in f\n",
    "#\n",
    "# vcf = pysam.VariantFile(VCF_URL, index_filename=LOCAL_TBI)\n",
    "# samples = list(vcf.header.samples)\n",
    "# n_samples = len(samples)\n",
    "# pairs, window = [], []\n",
    "# for rec in tqdm(vcf.fetch(CONTIG), desc=\"Scanning \" + CONTIG):\n",
    "#     if not is_pass(rec) or (not is_biallelic_snv(rec)): continue\n",
    "#     pos, ref, alt = rec.pos, rec.ref, rec.alts[0]\n",
    "#     AF = rec.info.get(\"AF\", np.nan)\n",
    "#     if isinstance(AF, (list, tuple)): AF = AF[0] if AF else np.nan\n",
    "#     carriers = np.array([any((a is not None) and (a >= 1) for a in rec.samples[s].get(\"GT\") or ()) for s in samples], dtype=bool)\n",
    "#     n_carriers = int(carriers.sum())\n",
    "#     window = [w for w in window if pos - w[\"pos\"] <= MAX_DIST]\n",
    "#     for w in window:\n",
    "#         dist = pos - w[\"pos\"]\n",
    "#         if dist <= 0 or dist > MAX_DIST: continue\n",
    "#         both = int((carriers & w[\"carriers\"]).sum())\n",
    "#         pairs.append({\"Chromosome\": CONTIG, \"pos1\": w[\"pos\"], \"pos2\": pos, \"distance_bp\": dist,\n",
    "#                       \"ref1\": w[\"ref\"], \"alt1\": w[\"alt\"], \"ref2\": ref, \"alt2\": alt,\n",
    "#                       \"AF1\": w[\"AF\"], \"AF2\": AF, \"n_carriers1\": w[\"n_carriers\"], \"n_carriers2\": n_carriers, \"n_carriers_both\": both,\n",
    "#                       \"pair_source\": \"g1k_chr12\", \"pair_type\": \"population_double_candidate\"})\n",
    "#     window.append({\"pos\": pos, \"ref\": ref, \"alt\": alt, \"AF\": AF, \"carriers\": carriers, \"n_carriers\": n_carriers})\n",
    "# benign_pairs_chr12 = pd.DataFrame(pairs).sort_values([\"pos1\", \"pos2\"]).reset_index(drop=True)\n",
    "# benign_pairs_chr12.to_csv(\"g1k_chr12_double_variants_max100bp.csv\", index=False)\n",
    "# print(\"Saved g1k_chr12_double_variants_max100bp.csv\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
