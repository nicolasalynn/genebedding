{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Epistasis data aggregation\n",
        "\n",
        "Build **one epistasis dataframe** from all structured subset CSVs, with a **`source`** column indicating the analysis/source. This file is intended to be fed into the pipeline that uses `add_epistasis_metrics` (or equivalent):\n",
        "\n",
        "- **Downstream usage:** Variants from the **same source** are processed together and stored in **their own database directory**, e.g. `embeddings/kras/`, `embeddings/fas/`, each containing one SQLite DB per tool (e.g. `nt100_multi.db`, `borzoi.db`). So you group the aggregated table by `source`, and for each source run the embedding + metrics pipeline writing to `embeddings/{source}/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure repo root is on path so \"notebooks\" can be imported\n",
        "ROOT = Path.cwd()\n",
        "for _ in range(4):\n",
        "    if (ROOT / \"notebooks\" / \"paper_data_config.py\").exists():\n",
        "        break\n",
        "    ROOT = ROOT.parent\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "# All data under paper root (set EPISTASIS_PAPER_ROOT env to override)\n",
        "from notebooks.paper_data_config import data_dir\n",
        "DATA_DIR = data_dir()  # EPISTASIS_PAPER_ROOT / \"data\"\n",
        "\n",
        "# Output: single aggregated file in DATA_DIR\n",
        "OUT_AGGREGATED = \"epistasis_aggregated.csv\"\n",
        "\n",
        "# (filename or path, source label). resolve_path looks in DATA_DIR, then parent, then cwd.\n",
        "SUBSETS = [\n",
        "    (\"kras_neighborhood_doubles.csv\", \"kras\"),\n",
        "    (\"fas_subset.csv\", \"fas\"),\n",
        "    (\"mst1r_subset.csv\", \"mst1r\"),\n",
        "    (\"cftr_folding_pairs.csv\", \"cftr_folding\"),\n",
        "    (\"okgp_epistasis.csv\", \"okgp\"),\n",
        "    (\"okgp_doubles_subset.csv\", \"okgp\"),  # fallback if okgp_epistasis not present\n",
        "    (\"tcga_subset_doubles.csv\", \"tcga\"),\n",
        "    (\"topld_doubles_subset_clean.csv\", \"topld\"),\n",
        "    (\"lt6000_eqtl_connected.csv\", \"eqtl_functional\"),\n",
        "    (\"correlated_variants_27K.csv\", \"eqtl_null\"),\n",
        "    (\"mrna_folding_epistasis.csv\", \"mrna_folding\"),  # from mrna_folding_epistasis.ipynb\n",
        "]\n",
        "\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load each subset and add `source`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def resolve_path(name):\n",
        "    for base in [Path(DATA_DIR), Path(DATA_DIR).parent, Path(\".\")]:\n",
        "        p = base / name\n",
        "        if p.is_file():\n",
        "            return str(p)\n",
        "    return None\n",
        "\n",
        "def load_subset(path, source_label):\n",
        "    df = pd.read_csv(path)\n",
        "    if \"epistasis_id\" not in df.columns:\n",
        "        if \"mut1\" in df.columns and \"mut2\" in df.columns:\n",
        "            df[\"epistasis_id\"] = df[\"mut1\"].astype(str) + \"|\" + df[\"mut2\"].astype(str)\n",
        "        else:\n",
        "            raise ValueError(f\"No epistasis_id or mut1/mut2 in {path}\")\n",
        "    df[\"source\"] = source_label\n",
        "    return df\n",
        "\n",
        "seen_sources = set()\n",
        "frames = []\n",
        "for name, source_label in SUBSETS:\n",
        "    path = resolve_path(name)\n",
        "    if path is None:\n",
        "        continue\n",
        "    # Avoid loading same source twice (e.g. okgp_epistasis and okgp_doubles_subset)\n",
        "    if source_label in seen_sources:\n",
        "        continue\n",
        "    try:\n",
        "        df = load_subset(path, source_label)\n",
        "        frames.append(df)\n",
        "        seen_sources.add(source_label)\n",
        "        print(f\"Loaded {len(df)} rows from {name} -> source={source_label}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Skip {name}: {e}\")\n",
        "        continue\n",
        "\n",
        "if not frames:\n",
        "    raise SystemExit(\"No subset files found. Check DATA_DIR and SUBSETS paths.\")\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concatenate and normalize columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Keep at least epistasis_id and source; optionally keep common columns if present\n",
        "COMMON_COLS = [\"epistasis_id\", \"source\", \"mut1\", \"mut2\", \"gene\", \"chrom\", \"pos1\", \"pos2\", \"distance\"]\n",
        "\n",
        "agg = pd.concat(frames, ignore_index=True)\n",
        "# Ensure required columns\n",
        "assert agg[\"epistasis_id\"].notna().all(), \"epistasis_id must be non-null\"\n",
        "agg[\"epistasis_id\"] = agg[\"epistasis_id\"].astype(str)\n",
        "\n",
        "# Optional: restrict to common columns that exist (so schema is consistent)\n",
        "cols_to_keep = [c for c in COMMON_COLS if c in agg.columns]\n",
        "agg = agg[cols_to_keep].copy()\n",
        "\n",
        "agg = agg.drop_duplicates(subset=[\"epistasis_id\", \"source\"])\n",
        "agg = agg.sort_values([\"source\", \"epistasis_id\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"Shape:\", agg.shape)\n",
        "print(agg.groupby(\"source\").size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save aggregated file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "out_path = Path(DATA_DIR) / OUT_AGGREGATED\n",
        "agg.to_csv(out_path, index=False)\n",
        "print(f\"Saved {len(agg)} rows to {out_path}\")\n",
        "agg.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Downstream: process by source and store per-source DBs\n",
        "\n",
        "Use the aggregated file so that **each source** is processed and written to its **own directory** of SQLite DBs (one per tool):\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from genebeddings.genebeddings import add_epistasis_metrics, VariantEmbeddingDB\n",
        "\n",
        "agg = pd.read_csv(\"epistasis_aggregated.csv\")\n",
        "BASE_DB_DIR = \"embeddings\"  # or your root for tool DBs\n",
        "\n",
        "for source, sub_df in agg.groupby(\"source\"):\n",
        "    out_dir = os.path.join(BASE_DB_DIR, source)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    # For each tool, db path = out_dir / f\"{tool_name}.db\"\n",
        "    # db = VariantEmbeddingDB(os.path.join(out_dir, \"nt100_multi.db\"))\n",
        "    # new_data = add_epistasis_metrics(sub_df, db, id_col=\"epistasis_id\", ...)\n",
        "```\n",
        "\n",
        "Resulting layout: `embeddings/kras/nt100_multi.db`, `embeddings/kras/borzoi.db`, `embeddings/fas/nt100_multi.db`, etc."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}