{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run full epistasis pipeline\n",
        "\n",
        "1. **Process sources** (null first, then others): for each source and each model, compute embeddings and write `{output_base}/{source}/{model_key}.db`. After the **null** source is done, null covariance is computed from `null/*.db` and saved under `{output_base}/null_cov/{model_key}_pack.npz`. That **null cov_inv is passed into add_epistasis_metrics** when processing every non-null source so that epistasis metrics include Mahalanobis terms (epi_mahal, mahal_obs, mahal_add, etc.) relative to the null background. SpliceAI runs only for splicing sources (fas_analysis, mst1r_analysis, kras). Uses batched `add_epistasis_metrics(batch_size=..., cov_inv=null_cov_inv)`.\n",
        "\n",
        "2. **Optional combined covariance**: Step 2 computes cov from all source DBs combined and saves `{model_key}_pack.npz` in OUTPUT_BASE for other uses.\n",
        "\n",
        "Set paths and options below, then run all cells.\n",
        "\n",
        "**Environment control:** Different models need different conda/envs (e.g. AlphaGenome needs JAX, Evo2 its own stack). Set **ENV_PROFILE** in the config cell and run this notebook in the matching environment:\n",
        "- `\"alphagenome\"` — run only AlphaGenome (use AlphaGenome env)\n",
        "- `\"evo2\"` — run only Evo2 (use Evo2 env)\n",
        "- `\"main\"` — run all other models (shared env; excludes alphagenome & evo2)\n",
        "- `\"all\"` — run every model (only if all deps in one env)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Config: paths and options\n",
        "# ---------------------------------------------------------------------------\n",
        "# Run with project root as current working directory (so \"from notebooks.process_epistasis\" works).\n",
        "# All data (embeddings, CSVs) lives under EPISTASIS_PAPER_ROOT. Override with env EPISTASIS_PAPER_ROOT.\n",
        "from pathlib import Path\n",
        "from notebooks.process_epistasis import get_model_keys_for_env\n",
        "from notebooks.paper_data_config import EPISTASIS_PAPER_ROOT, data_dir, embeddings_dir\n",
        "\n",
        "# Environment profile: which models to run in *this* environment.\n",
        "#   \"alphagenome\" -> only AlphaGenome (use in AlphaGenome conda env)\n",
        "#   \"evo2\"       -> only Evo2 (use in Evo2 conda env)\n",
        "#   \"main\"       -> all models except alphagenome & evo2 (shared env)\n",
        "#   \"all\"        -> every model (only if all deps in one env)\n",
        "ENV_PROFILE = \"main\"  # <-- single point of control: change per environment\n",
        "MODEL_KEYS = get_model_keys_for_env(ENV_PROFILE)\n",
        "print(f\"ENV_PROFILE={ENV_PROFILE!r} -> MODEL_KEYS={MODEL_KEYS}\")\n",
        "print(f\"Data root: {EPISTASIS_PAPER_ROOT}\")\n",
        "\n",
        "# (source_name, path_to_csv). Paths under paper data root/data/\n",
        "SOURCES = [\n",
        "    (\"null\", data_dir() / \"null_epistasis.csv\"),\n",
        "    (\"fas_analysis\", data_dir() / \"fas_subset.csv\"),\n",
        "    (\"mst1r_analysis\", data_dir() / \"mst1r_subset.csv\"),\n",
        "    (\"kras\", data_dir() / \"kras_subset.csv\"),\n",
        "    # (\"tcga_analysis\", data_dir() / \"tcga_subset_doubles.csv\"),\n",
        "    # (\"okgp_analysis\", data_dir() / \"okgp_subset_clean.csv\"),\n",
        "]\n",
        "\n",
        "OUTPUT_BASE = embeddings_dir()\n",
        "ID_COL = \"epistasis_id\"\n",
        "BATCH_SIZE = 8  # add_epistasis_metrics batch_size (e.g. 8 => 32 sequences per batch)\n",
        "\n",
        "# OpenSpliceAI checkpoint dir for SpliceAI (or set env OPENSPLICEAI_MODEL_DIR)\n",
        "SPLICEAI_MODEL_DIR = None  # e.g. \"/path/to/openspliceai-mane/10000nt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Step 1: Process all sources (null first); one .db per model per source\n",
        "# ---------------------------------------------------------------------------\n",
        "import logging\n",
        "from notebooks.process_epistasis import run_sources\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "run_sources(\n",
        "    SOURCES,\n",
        "    output_base=OUTPUT_BASE,\n",
        "    model_keys=MODEL_KEYS,\n",
        "    spliceai_model_dir=SPLICEAI_MODEL_DIR,\n",
        "    id_col=ID_COL,\n",
        "    show_progress=True,\n",
        "    force=False,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Step 2: Compute covariance from combined DBs (optional) and save .npz packs\n",
        "# ---------------------------------------------------------------------------\n",
        "# Null covariance is already computed and saved in OUTPUT_BASE / \"null_cov\" during\n",
        "# Step 1; it is passed into add_epistasis_metrics when processing non-null sources.\n",
        "# Optionally compute a combined cov from all sources (null + others) for other uses:\n",
        "from notebooks.process_epistasis import run_covariance_and_save\n",
        "\n",
        "source_names = [name for name, _ in SOURCES]\n",
        "saved_npz = run_covariance_and_save(\n",
        "    OUTPUT_BASE,\n",
        "    source_names,\n",
        "    model_keys=MODEL_KEYS,\n",
        "    out_npz_dir=OUTPUT_BASE,\n",
        "    method=\"ledoit_wolf\",\n",
        "    show_progress=True,\n",
        ")\n",
        "print(\"Saved combined cov packs:\", saved_npz)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Optional: inspect null covariance pack (this cov_inv is passed to add_epistasis_metrics)\n",
        "# ---------------------------------------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "null_cov_dir = OUTPUT_BASE / \"null_cov\"\n",
        "tool_name = \"nt500_multi\"\n",
        "null_pack_path = null_cov_dir / f\"{tool_name}_pack.npz\"\n",
        "if null_pack_path.exists():\n",
        "    data = np.load(null_pack_path, allow_pickle=True)\n",
        "    cov = data[\"cov\"]\n",
        "    cov_inv = data[\"cov_inv\"]\n",
        "    print(f\"Null cov ({tool_name}): cov {cov.shape}, cov_inv {cov_inv.shape}\")\n",
        "    print(\"Used as cov_inv in add_epistasis_metrics for non-null sources (epi_mahal, etc.)\")\n",
        "else:\n",
        "    print(f\"No null pack at {null_pack_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Optional: inspect combined covariance pack (from Step 2)\n",
        "# ---------------------------------------------------------------------------\n",
        "# Null packs live in OUTPUT_BASE / \"null_cov\"; combined packs in OUTPUT_BASE.\n",
        "tool_name = \"nt500_multi\"  # or alphagenome, spliceai, etc.\n",
        "pack_path = OUTPUT_BASE / f\"{tool_name}_pack.npz\"\n",
        "if pack_path.exists():\n",
        "    data = np.load(pack_path, allow_pickle=True)\n",
        "    cov = data[\"cov\"]\n",
        "    cov_inv = data[\"cov_inv\"]\n",
        "    print(f\"{tool_name}: cov {cov.shape}, cov_inv {cov_inv.shape}\")\n",
        "    print(\"model:\", data[\"model\"])\n",
        "    print(\"pool:\", data[\"pool\"])\n",
        "else:\n",
        "    print(f\"No pack at {pack_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}