{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genomic Model Wrappers Usage Guide\n",
    "\n",
    "This notebook provides comprehensive examples of how to use each wrapper in the genebeddings package.\n",
    "All wrappers implement the standardized `BaseWrapper` API for consistent usage across different models.\n",
    "\n",
    "## Table of Contents\n",
    "1. [BaseWrapper API Overview](#BaseWrapper-API-Overview)\n",
    "2. [NTWrapper (Nucleotide Transformer)](#NTWrapper)\n",
    "3. [CaduceusWrapper](#CaduceusWrapper)\n",
    "4. [BorzoiWrapper](#BorzoiWrapper)\n",
    "5. [SpeciesLMWrapper](#SpeciesLMWrapper)\n",
    "6. [RiNALMoWrapper](#RiNALMoWrapper)\n",
    "7. [ConformerWrapper](#ConformerWrapper)\n",
    "8. [ConvNovaWrapper](#ConvNovaWrapper)\n",
    "9. [Advanced Usage Examples](#Advanced-Usage)\n",
    "10. [Dependency Map Examples](#Dependency-Maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "\n",
    "# Test sequence - a realistic genomic sequence\n",
    "TEST_SEQUENCE = \"ATCGATCGATCGATCGATCGATCGATCGAAAAAAAAAAATTTTTTTTTTTCCCCCCCCCCGGGGGGGGGGAACCTTGGAACCTTGGAACCTTGGAACCTTGG\" * 10\n",
    "SHORT_SEQUENCE = \"ATCGATCGATCGATCGATCGATCG\"\n",
    "\n",
    "print(f\"Test sequence length: {len(TEST_SEQUENCE)}\")\n",
    "print(f\"Short sequence: {SHORT_SEQUENCE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseWrapper API Overview\n",
    "\n",
    "All wrappers implement the same standard interface:\n",
    "\n",
    "### Required Methods\n",
    "- **`embed(seq, pool='mean', return_numpy=True)`**: Generate sequence embeddings\n",
    "\n",
    "### Optional Methods (model-dependent)\n",
    "- **`predict_nucleotides(seq, positions)`**: Get nucleotide probabilities at masked positions\n",
    "- **`predict_tracks(seq)`**: Get genomic track predictions (Borzoi-style)\n",
    "\n",
    "### Utility Methods\n",
    "- **`get_capabilities()`**: List supported features\n",
    "- **`supports_capability(name)`**: Check if feature is supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_wrapper_capabilities(wrapper, name):\n",
    "    \"\"\"Demonstrate basic capabilities of any wrapper.\"\"\"\n",
    "    print(f\"\\n=== {name} Capabilities ===\")\n",
    "    print(f\"Supported features: {wrapper.get_capabilities()}\")\n",
    "    \n",
    "    # Test embedding\n",
    "    if wrapper.supports_capability('embed'):\n",
    "        print(\"\\nðŸ“Š Testing embedding functionality:\")\n",
    "        \n",
    "        # Mean pooled embedding\n",
    "        emb_mean = wrapper.embed(SHORT_SEQUENCE, pool='mean')\n",
    "        print(f\"  Mean pooled: {emb_mean.shape}\")\n",
    "        \n",
    "        # Token embeddings\n",
    "        emb_tokens = wrapper.embed(SHORT_SEQUENCE, pool='tokens')\n",
    "        print(f\"  Token level: {emb_tokens.shape}\")\n",
    "        \n",
    "        # CLS embedding (if supported)\n",
    "        try:\n",
    "            emb_cls = wrapper.embed(SHORT_SEQUENCE, pool='cls')\n",
    "            print(f\"  CLS token: {emb_cls.shape}\")\n",
    "        except:\n",
    "            print(f\"  CLS token: Not supported\")\n",
    "    \n",
    "    # Test nucleotide prediction\n",
    "    if wrapper.supports_capability('predict_nucleotides'):\n",
    "        print(\"\\nðŸ§¬ Testing nucleotide prediction:\")\n",
    "        try:\n",
    "            # Create a sequence with masked positions\n",
    "            masked_seq = SHORT_SEQUENCE[:10] + 'N' + SHORT_SEQUENCE[11:]\n",
    "            probs = wrapper.predict_nucleotides(masked_seq, positions=None)\n",
    "            print(f\"  Predictions at masked positions: {len(probs)} positions\")\n",
    "            if len(probs) > 0:\n",
    "                print(f\"  Sample prediction: {probs[0]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "    \n",
    "    # Test track prediction\n",
    "    if wrapper.supports_capability('predict_tracks'):\n",
    "        print(\"\\nðŸ“ˆ Testing track prediction:\")\n",
    "        try:\n",
    "            tracks = wrapper.predict_tracks(SHORT_SEQUENCE)\n",
    "            print(f\"  Track predictions: {tracks.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nâœ… {name} demo completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NTWrapper (Nucleotide Transformer)\n",
    "\n",
    "**Model**: Nucleotide Transformer v2 (500M parameters)  \n",
    "**Source**: HuggingFace (`InstaDeepAI/nucleotide-transformer-v2-500m-multi-species`)  \n",
    "**Tokenization**: k-mer based (typically k=6, non-overlapping)  \n",
    "**Capabilities**: Embeddings, nucleotide prediction  \n",
    "**Strengths**: Large pre-trained model, good for sequence understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from nt_wrapper import NTWrapper\n",
    "    \n",
    "    print(\"ðŸ”„ Loading NTWrapper...\")\n",
    "    nt_model = NTWrapper()\n",
    "    \n",
    "    # Basic capabilities demo\n",
    "    demo_wrapper_capabilities(nt_model, \"NTWrapper\")\n",
    "    \n",
    "    print(\"\\nðŸ”¬ NTWrapper-specific features:\")\n",
    "    \n",
    "    # Test k-mer tokenization\n",
    "    tokens = nt_model.tokens_from_seq(SHORT_SEQUENCE)\n",
    "    print(f\"K-mer tokens: {tokens.shape}\")\n",
    "    print(f\"Inferred k-mer size: {nt_model.k}\")\n",
    "    \n",
    "    # Test batch embeddings\n",
    "    sequences = [SHORT_SEQUENCE, SHORT_SEQUENCE[:15], SHORT_SEQUENCE + \"AAAA\"]\n",
    "    batch_embeddings = [nt_model.embed(seq, pool='mean') for seq in sequences]\n",
    "    print(f\"Batch embeddings: {len(batch_embeddings)} sequences\")\n",
    "    \n",
    "    # Test pattern matching (legacy feature)\n",
    "    try:\n",
    "        # Get logits for a masked position\n",
    "        tokens_no_specials = nt_model.tokens_from_seq(SHORT_SEQUENCE)\n",
    "        logits = nt_model.get_masked_position_logits(tokens_no_specials, 0)\n",
    "        print(f\"Logits shape: {logits.shape}\")\n",
    "        \n",
    "        # Pattern matching\n",
    "        pattern_result = nt_model.pattern_matching_filter(logits, \"ATCGNN\")\n",
    "        print(f\"Pattern matching result: {pattern_result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Pattern matching error: {e}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âŒ NTWrapper not available (missing dependencies)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ NTWrapper error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CaduceusWrapper\n",
    "\n",
    "**Model**: Caduceus (BiDirectional Mamba for DNA)  \n",
    "**Source**: HuggingFace (`kuleshov-group/caduceus-*`)  \n",
    "**Tokenization**: Character-level or k-mer (often k=1)  \n",
    "**Capabilities**: Embeddings, nucleotide prediction  \n",
    "**Strengths**: Long sequence support (~131k tokens), bidirectional architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from caduceus_wrapper import CaduceusWrapperOld as CaduceusWrapper\n",
    "    \n",
    "    print(\"ðŸ”„ Loading CaduceusWrapper...\")\n",
    "    caduceus_model = CaduceusWrapper()\n",
    "    \n",
    "    # Basic capabilities demo\n",
    "    demo_wrapper_capabilities(caduceus_model, \"CaduceusWrapper\")\n",
    "    \n",
    "    print(\"\\nðŸ”¬ CaduceusWrapper-specific features:\")\n",
    "    \n",
    "    # Test with long sequence\n",
    "    long_sequence = TEST_SEQUENCE[:1000]  # 1k bp test\n",
    "    long_emb = caduceus_model.embed(long_sequence, pool='mean')\n",
    "    print(f\"Long sequence embedding: {long_emb.shape}\")\n",
    "    \n",
    "    # Test character-level tokenization\n",
    "    tokens = caduceus_model.tokens_from_seq(SHORT_SEQUENCE)\n",
    "    print(f\"Tokens shape: {tokens.shape}\")\n",
    "    print(f\"Inferred k-mer size: {caduceus_model.k}\")\n",
    "    \n",
    "    # Test nucleotide prediction with multiple positions\n",
    "    masked_seq = \"ATCGNNNGATCG\"\n",
    "    predictions = caduceus_model.predict_nucleotides(masked_seq, positions=None)\n",
    "    print(f\"Multi-position predictions: {len(predictions)} positions\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âŒ CaduceusWrapper not available (missing dependencies)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ CaduceusWrapper error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BorzoiWrapper\n",
    "\n",
    "**Model**: Borzoi (Genomic Track Prediction)  \n",
    "**Source**: HuggingFace (`johahi/flashzoi-replicate-0`)  \n",
    "**Tokenization**: One-hot encoding (A/C/G/T â†’ 4 channels)  \n",
    "**Capabilities**: Embeddings, genomic track prediction  \n",
    "**Strengths**: Predicts chromatin accessibility, TF binding, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from borzoi_wrapper import BorzoiWrapper\n",
    "    \n",
    "    print(\"ðŸ”„ Loading BorzoiWrapper...\")\n",
    "    borzoi_model = BorzoiWrapper()\n",
    "    \n",
    "    # Basic capabilities demo\n",
    "    demo_wrapper_capabilities(borzoi_model, \"BorzoiWrapper\")\n",
    "    \n",
    "    print(\"\\nðŸ”¬ BorzoiWrapper-specific features:\")\n",
    "    \n",
    "    # Borzoi requires specific input length (524,288 bp by default)\n",
    "    print(f\"Required input length: {borzoi_model.input_len} bp\")\n",
    "    print(f\"Target output length: {borzoi_model.target_len} positions\")\n",
    "    \n",
    "    # Test with padded sequence\n",
    "    test_seq = TEST_SEQUENCE[:10000]  # Use first 10k bp\n",
    "    \n",
    "    # Get embeddings\n",
    "    embedding = borzoi_model.embed(test_seq, pool='mean')\n",
    "    print(f\"Embedding shape: {embedding.shape}\")\n",
    "    \n",
    "    # Get track predictions\n",
    "    tracks = borzoi_model.predict_tracks(test_seq)\n",
    "    print(f\"Track predictions shape: {tracks.shape}\")\n",
    "    print(f\"Number of tracks: {tracks.shape[0]}\")\n",
    "    print(f\"Number of positions: {tracks.shape[1]}\")\n",
    "    \n",
    "    # Visualize some tracks\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(min(5, tracks.shape[0])):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.plot(tracks[i, :100])  # First 100 positions\n",
    "        plt.title(f'Track {i}')\n",
    "        plt.xlabel('Position')\n",
    "        plt.ylabel('Signal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âŒ BorzoiWrapper not available (missing borzoi_pytorch package)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ BorzoiWrapper error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpeciesLMWrapper\n",
    "\n",
    "**Model**: SpeciesLM (Species-aware Language Model)  \n",
    "**Source**: HuggingFace (`gagneurlab/SpeciesLM`)  \n",
    "**Tokenization**: k=6 overlapping k-mers (stride=1)  \n",
    "**Capabilities**: Embeddings, nucleotide prediction  \n",
    "**Strengths**: Species conditioning, automatic chunking for long sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from specieslm_wrapper import SpeciesLMWrapper\n",
    "    \n",
    "    print(\"ðŸ”„ Loading SpeciesLMWrapper...\")\n",
    "    specieslm_model = SpeciesLMWrapper()\n",
    "    \n",
    "    # Basic capabilities demo\n",
    "    demo_wrapper_capabilities(specieslm_model, \"SpeciesLMWrapper\")\n",
    "    \n",
    "    print(\"\\nðŸ”¬ SpeciesLMWrapper-specific features:\")\n",
    "    \n",
    "    print(f\"Max tokens per chunk: {specieslm_model.max_model_tokens}\")\n",
    "    print(f\"Window size: ~{specieslm_model.window_size} nucleotides\")\n",
    "    \n",
    "    # Test chunking with long sequence\n",
    "    long_seq = TEST_SEQUENCE[:2000]  # 2k bp sequence\n",
    "    chunks = specieslm_model._chunk_sequence(long_seq)\n",
    "    print(f\"Chunked {len(long_seq)} bp into {len(chunks)} chunks\")\n",
    "    \n",
    "    # Test embedding with chunking\n",
    "    long_emb = specieslm_model.embed(long_seq, pool='mean')\n",
    "    print(f\"Long sequence embedding: {long_emb.shape}\")\n",
    "    \n",
    "    # Test full sequence probability matrix\n",
    "    short_seq = SHORT_SEQUENCE[:50]  # Use shorter sequence for demo\n",
    "    prob_matrix = specieslm_model.acgt_probs(short_seq)\n",
    "    print(f\"Probability matrix: {prob_matrix.shape}\")\n",
    "    \n",
    "    # Visualize probability matrix\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.imshow(prob_matrix.T, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Probability')\n",
    "    plt.xlabel('Position')\n",
    "    plt.ylabel('Nucleotide')\n",
    "    plt.yticks([0, 1, 2, 3], ['A', 'C', 'G', 'T'])\n",
    "    plt.title('Nucleotide Probabilities Across Sequence')\n",
    "    plt.show()\n",
    "    \n",
    "    # Test species conditioning\n",
    "    try:\n",
    "        species_emb = specieslm_model.embed(SHORT_SEQUENCE, pool='mean', species_proxy='human')\n",
    "        print(f\"Species-conditioned embedding: {species_emb.shape}\")\n",
    "    except:\n",
    "        print(\"Species conditioning not available\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âŒ SpeciesLMWrapper not available (missing dependencies)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ SpeciesLMWrapper error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RiNALMoWrapper\n",
    "\n",
    "**Model**: RiNALMo (RNA Language Model)  \n",
    "**Source**: Pretrained via `rinalmo` package  \n",
    "**Tokenization**: Character-level (k=1)  \n",
    "**Capabilities**: Embeddings, nucleotide prediction  \n",
    "**Strengths**: RNA-specialized, handles Tâ†”U conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from rinalmo_wrapper import RiNALMoWrapper\n",
    "    \n",
    "    print(\"ðŸ”„ Loading RiNALMoWrapper...\")\n",
    "    rinalmo_model = RiNALMoWrapper()\n",
    "    \n",
    "    # Basic capabilities demo\n",
    "    demo_wrapper_capabilities(rinalmo_model, \"RiNALMoWrapper\")\n",
    "    \n",
    "    print(\"\\nðŸ”¬ RiNALMoWrapper-specific features:\")\n",
    "    \n",
    "    # Test RNA vs DNA handling\n",
    "    dna_seq = \"ATCGATCG\"\n",
    "    rna_seq = \"AUCGAUCG\"\n",
    "    \n",
    "    dna_emb = rinalmo_model.embed(dna_seq, pool='mean')\n",
    "    rna_emb = rinalmo_model.embed(rna_seq, pool='mean')\n",
    "    \n",
    "    print(f\"DNA embedding: {dna_emb.shape}\")\n",
    "    print(f\"RNA embedding: {rna_emb.shape}\")\n",
    "    \n",
    "    # Check if model uses RNA vocabulary\n",
    "    print(f\"Model uses RNA vocab: {rinalmo_model.model_uses_rna_vocab}\")\n",
    "    print(f\"DNA output enabled: {rinalmo_model.dna_output}\")\n",
    "    \n",
    "    # Test batch processing\n",
    "    sequences = [dna_seq, rna_seq, \"AAAUUUGGCCCC\"]\n",
    "    batch_embeddings = [rinalmo_model.embed(seq, pool='mean') for seq in sequences]\n",
    "    print(f\"Batch processing: {len(batch_embeddings)} sequences\")\n",
    "    \n",
    "    # Test nucleotide prediction\n",
    "    masked_seq = \"ATCGNGATCG\"\n",
    "    predictions = rinalmo_model.predict_nucleotides(masked_seq, positions=None)\n",
    "    print(f\"Nucleotide predictions: {len(predictions)} positions\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âŒ RiNALMoWrapper not available (missing rinalmo package)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ RiNALMoWrapper error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConformerWrapper\n",
    "\n",
    "**Model**: Conformer-based genomic model (base-anchored)  \n",
    "**Source**: Local model files (required)  \n",
    "**Tokenization**: k=1 with base-anchored GenomicBPE  \n",
    "**Capabilities**: Embeddings, nucleotide prediction  \n",
    "**Strengths**: Local deployment, base-anchored tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from conformer_wrapper import ConformerWrapper\n",
    "    \n",
    "    # ConformerWrapper requires local model files\n",
    "    # You'll need to provide paths to your local model\n",
    "    tokenizer_path = \"/path/to/your/tokenizer.tkz\"\n",
    "    checkpoint_path = \"/path/to/your/model.pt\"\n",
    "    \n",
    "    print(\"ðŸ”„ Loading ConformerWrapper...\")\n",
    "    print(\"âš ï¸  Note: Requires local model files\")\n",
    "    \n",
    "    # Uncomment and modify paths if you have local model files\n",
    "    \"\"\"\n",
    "    conformer_model = ConformerWrapper(\n",
    "        tokenizer_path=tokenizer_path,\n",
    "        checkpoint_path=checkpoint_path\n",
    "    )\n",
    "    \n",
    "    # Basic capabilities demo\n",
    "    demo_wrapper_capabilities(conformer_model, \"ConformerWrapper\")\n",
    "    \n",
    "    print(\"\\nðŸ”¬ ConformerWrapper-specific features:\")\n",
    "    \n",
    "    # Test base-anchored tokenization\n",
    "    print(f\"Base-anchored tokenization (k=1): {conformer_model.k}\")\n",
    "    \n",
    "    # Test DataParallel support\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Multi-GPU support: {torch.cuda.device_count()} GPUs available\")\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ðŸ“ To use ConformerWrapper:\")\n",
    "    print(\"   1. Obtain tokenizer (.tkz) and checkpoint (.pt) files\")\n",
    "    print(\"   2. Install genomenet dependencies (anchor_tokenizer, conformer)\")\n",
    "    print(\"   3. Update tokenizer_path and checkpoint_path variables above\")\n",
    "    print(\"   4. Uncomment the code block\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âŒ ConformerWrapper not available (missing genomenet dependencies)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ConformerWrapper error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNovaWrapper\n",
    "\n",
    "**Model**: ConvNova (Dilated CNN model)  \n",
    "**Source**: Optional local checkpoint  \n",
    "**Tokenization**: k=1 base-level  \n",
    "**Capabilities**: Embeddings, nucleotide prediction  \n",
    "**Strengths**: Can work without checkpoint, efficient CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from convnova_wrapper import ConvNovaWrapper\n",
    "    \n",
    "    print(\"ðŸ”„ Loading ConvNovaWrapper...\")\n",
    "    # Can work without checkpoint (uses random initialization)\n",
    "    convnova_model = ConvNovaWrapper()\n",
    "    \n",
    "    # Basic capabilities demo\n",
    "    demo_wrapper_capabilities(convnova_model, \"ConvNovaWrapper\")\n",
    "    \n",
    "    print(\"\\nðŸ”¬ ConvNovaWrapper-specific features:\")\n",
    "    \n",
    "    # Test base-level tokenization\n",
    "    tokens = convnova_model.tokens_from_seq(SHORT_SEQUENCE)\n",
    "    print(f\"Base-level tokens: {tokens.shape}\")\n",
    "    print(f\"Token k-mer size: {convnova_model.k}\")\n",
    "    \n",
    "    # Test CNN architecture info\n",
    "    print(f\"Model architecture: Dilated CNN\")\n",
    "    \n",
    "    # Test with longer sequence\n",
    "    longer_seq = TEST_SEQUENCE[:500]\n",
    "    longer_emb = convnova_model.embed(longer_seq, pool='mean')\n",
    "    print(f\"Longer sequence embedding: {longer_emb.shape}\")\n",
    "    \n",
    "    # Test nucleotide prediction\n",
    "    masked_seq = \"ATCGNNNGATCG\"\n",
    "    predictions = convnova_model.predict_nucleotides(masked_seq, positions=None)\n",
    "    print(f\"Predictions: {len(predictions)} masked positions\")\n",
    "    \n",
    "    # Note about checkpoints\n",
    "    print(\"\\nðŸ“ Note: Currently using random initialization\")\n",
    "    print(\"   For trained model, provide checkpoint_path parameter\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âŒ ConvNovaWrapper not available (missing dependencies)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ConvNovaWrapper error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage Examples\n",
    "\n",
    "Here are some advanced patterns for using the wrappers effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_embeddings(models_dict, sequence):\n",
    "    \"\"\"Compare embeddings across different models.\"\"\"\n",
    "    embeddings = {}\n",
    "    \n",
    "    print(f\"ðŸ”¬ Comparing embeddings for sequence: {sequence[:30]}...\")\n",
    "    \n",
    "    for name, model in models_dict.items():\n",
    "        try:\n",
    "            if model.supports_capability('embed'):\n",
    "                emb = model.embed(sequence, pool='mean')\n",
    "                embeddings[name] = emb\n",
    "                print(f\"  {name}: {emb.shape}, mean={emb.mean():.4f}, std={emb.std():.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {name}: Error - {e}\")\n",
    "    \n",
    "    # Compute pairwise similarities\n",
    "    if len(embeddings) > 1:\n",
    "        print(\"\\nðŸ“Š Pairwise cosine similarities:\")\n",
    "        names = list(embeddings.keys())\n",
    "        for i, name1 in enumerate(names):\n",
    "            for j, name2 in enumerate(names[i+1:], i+1):\n",
    "                emb1, emb2 = embeddings[name1], embeddings[name2]\n",
    "                # Ensure same length for comparison\n",
    "                min_len = min(len(emb1), len(emb2))\n",
    "                similarity = np.dot(emb1[:min_len], emb2[:min_len]) / (np.linalg.norm(emb1[:min_len]) * np.linalg.norm(emb2[:min_len]))\n",
    "                print(f\"  {name1} vs {name2}: {similarity:.4f}\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "def benchmark_prediction_accuracy(models_dict, test_sequences):\n",
    "    \"\"\"Benchmark nucleotide prediction accuracy.\"\"\"\n",
    "    print(\"ðŸŽ¯ Benchmarking nucleotide prediction accuracy...\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models_dict.items():\n",
    "        if not model.supports_capability('predict_nucleotides'):\n",
    "            continue\n",
    "            \n",
    "        accuracies = []\n",
    "        \n",
    "        for seq in test_sequences:\n",
    "            # Mask random position\n",
    "            mask_pos = len(seq) // 2\n",
    "            true_base = seq[mask_pos]\n",
    "            masked_seq = seq[:mask_pos] + 'N' + seq[mask_pos+1:]\n",
    "            \n",
    "            try:\n",
    "                predictions = model.predict_nucleotides(masked_seq, positions=None)\n",
    "                if len(predictions) > 0:\n",
    "                    pred_dict = predictions[0]\n",
    "                    predicted_base = max(pred_dict.keys(), key=lambda k: pred_dict[k])\n",
    "                    accuracies.append(1.0 if predicted_base == true_base else 0.0)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if accuracies:\n",
    "            avg_accuracy = np.mean(accuracies)\n",
    "            results[name] = avg_accuracy\n",
    "            print(f\"  {name}: {avg_accuracy:.3f} accuracy ({len(accuracies)} tests)\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compare available models\n",
    "available_models = {}\n",
    "\n",
    "# Add models that were successfully loaded above\n",
    "# Note: In practice, you'd check which models are available\n",
    "\n",
    "try:\n",
    "    if 'nt_model' in locals():\n",
    "        available_models['NT'] = nt_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if 'caduceus_model' in locals():\n",
    "        available_models['Caduceus'] = caduceus_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if 'specieslm_model' in locals():\n",
    "        available_models['SpeciesLM'] = specieslm_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if 'convnova_model' in locals():\n",
    "        available_models['ConvNova'] = convnova_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(f\"Available models for comparison: {list(available_models.keys())}\")\n",
    "\n",
    "if available_models:\n",
    "    # Compare embeddings\n",
    "    test_seq = \"ATCGATCGATCGATCGATCGATCGATCG\"\n",
    "    embeddings = compare_embeddings(available_models, test_seq)\n",
    "    \n",
    "    # Benchmark prediction accuracy\n",
    "    test_sequences = [\n",
    "        \"ATCGATCGATCGATCG\",\n",
    "        \"AAATTTGGGCCCAAATTT\", \n",
    "        \"GCTAGCTAGCTAGCTA\"\n",
    "    ]\n",
    "    accuracies = benchmark_prediction_accuracy(available_models, test_sequences)\nelse:\n",
    "    print(\"âŒ No models available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Map Examples\n",
    "\n",
    "Demonstrate the dependency map functionality with the available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from dependency_map import compute_dependency_map, plot_dependency_map\n",
    "    \n",
    "    print(\"ðŸ—ºï¸  Testing dependency map functionality...\")\n",
    "    \n",
    "    # Use a model that supports both embedding and nucleotide prediction\n",
    "    test_model = None\n",
    "    model_name = \"None\"\n",
    "    \n",
    "    for name, model in available_models.items():\n",
    "        if model.supports_capability('embed') and model.supports_capability('predict_nucleotides'):\n",
    "            test_model = model\n",
    "            model_name = name\n",
    "            break\n",
    "    \n",
    "    if test_model is None:\n",
    "        # Fall back to embedding-only model\n",
    "        for name, model in available_models.items():\n",
    "            if model.supports_capability('embed'):\n",
    "                test_model = model\n",
    "                model_name = name\n",
    "                break\n",
    "    \n",
    "    if test_model is not None:\n",
    "        print(f\"Using {model_name} for dependency map demo\")\n",
    "        \n",
    "        # Test sequence - use a shorter sequence for demo\n",
    "        dep_test_seq = \"ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG\"  # 42 bp\n",
    "        \n",
    "        # Method 1: Mutual information (works with embedding-only models)\n",
    "        print(\"\\nðŸ”¬ Computing mutual information dependency map...\")\n",
    "        dep_mutual = compute_dependency_map(\n",
    "            dep_test_seq,\n",
    "            test_model,\n",
    "            method=\"mutual_info\",\n",
    "            range_start=5,\n",
    "            range_end=25,  # 20x20 matrix\n",
    "            embedding_distance=\"euclidean\"\n",
    "        )\n",
    "        \n",
    "        print(f\"Dependency matrix shape: {dep_mutual.shape}\")\n",
    "        print(f\"Value range: [{dep_mutual.min():.4f}, {dep_mutual.max():.4f}]\")\n",
    "        \n",
    "        # Plot the dependency map\n",
    "        fig = plot_dependency_map(\n",
    "            dep_mutual,\n",
    "            sequence=dep_test_seq[5:25],  # Corresponding sequence region\n",
    "            title=f\"Mutual Information Dependency Map ({model_name})\"\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Method 2: Epistatic interactions (if model supports both capabilities)\n",
    "        if test_model.supports_capability('predict_nucleotides'):\n",
    "            print(\"\\nðŸ§¬ Computing epistatic dependency map...\")\n",
    "            \n",
    "            # Use smaller region for computational efficiency\n",
    "            dep_epistatic = compute_dependency_map(\n",
    "                dep_test_seq,\n",
    "                test_model,\n",
    "                method=\"epistatic\",\n",
    "                range_start=10,\n",
    "                range_end=20,  # 10x10 matrix\n",
    "                embedding_distance=\"euclidean\"\n",
    "            )\n",
    "            \n",
    "            print(f\"Epistatic matrix shape: {dep_epistatic.shape}\")\n",
    "            print(f\"Value range: [{dep_epistatic.min():.4f}, {dep_epistatic.max():.4f}]\")\n",
    "            \n",
    "            fig = plot_dependency_map(\n",
    "                dep_epistatic,\n",
    "                sequence=dep_test_seq[10:20],\n",
    "                title=f\"Epistatic Dependency Map ({model_name})\"\n",
    "            )\n",
    "            plt.show()\n",
    "        \n",
    "        # Method 3: Log probabilities (if model supports nucleotide prediction)\n",
    "        if test_model.supports_capability('predict_nucleotides'):\n",
    "            print(\"\\nðŸ“Š Computing logprobs dependency map...\")\n",
    "            \n",
    "            dep_logprobs = compute_dependency_map(\n",
    "                dep_test_seq,\n",
    "                test_model,\n",
    "                method=\"logprobs\",\n",
    "                range_start=12,\n",
    "                range_end=20,  # 8x8 matrix\n",
    "            )\n",
    "            \n",
    "            print(f\"Logprobs matrix shape: {dep_logprobs.shape}\")\n",
    "            print(f\"Value range: [{dep_logprobs.min():.4f}, {dep_logprobs.max():.4f}]\")\n",
    "            \n",
    "            fig = plot_dependency_map(\n",
    "                dep_logprobs,\n",
    "                sequence=dep_test_seq[12:20],\n",
    "                title=f\"Log-Probability Dependency Map ({model_name})\"\n",
    "            )\n",
    "            plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(\"âŒ No suitable model available for dependency map demo\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"âŒ Dependency map module not available\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Dependency map error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### Model Selection Guide\n",
    "\n",
    "| Use Case | Recommended Model(s) | Notes |\n",
    "|----------|----------------------|-------|\n",
    "| **General sequence embedding** | NTWrapper, CaduceusWrapper | Large pretrained models |\n",
    "| **Long sequences (>100k bp)** | CaduceusWrapper | Supports ~131k tokens |\n",
    "| **Nucleotide prediction** | NTWrapper, SpeciesLMWrapper | Strong MLM capabilities |\n",
    "| **Genomic tracks/signals** | BorzoiWrapper | Specialized for chromatin/TF prediction |\n",
    "| **Species-specific analysis** | SpeciesLMWrapper | Built-in species conditioning |\n",
    "| **RNA sequences** | RiNALMoWrapper | Handles Tâ†”U conversion |\n",
    "| **Local/custom models** | ConformerWrapper, ConvNovaWrapper | For proprietary models |\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "1. **Batch processing**: Use list comprehensions for multiple sequences\n",
    "2. **Memory management**: Use appropriate pooling (`mean` vs `tokens`)\n",
    "3. **GPU utilization**: Models automatically use available GPUs\n",
    "4. **Sequence length**: Check model-specific limits and chunking behavior\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "```python\n",
    "# Pattern 1: Check capabilities before use\n",
    "if model.supports_capability('predict_nucleotides'):\n",
    "    predictions = model.predict_nucleotides(masked_seq, positions=None)\n",
    "\n",
    "# Pattern 2: Handle different pooling strategies\n",
    "global_emb = model.embed(seq, pool='mean')      # Global representation\n",
    "position_embs = model.embed(seq, pool='tokens') # Position-wise embeddings\n",
    "\n",
    "# Pattern 3: Robust error handling\n",
    "try:\n",
    "    result = model.predict_nucleotides(seq, positions=None)\n",
    "except NotImplementedError:\n",
    "    print(f\"Model doesn't support nucleotide prediction\")\n",
    "```\n",
    "\n",
    "This notebook provides a comprehensive overview of all wrapper functionality. Each wrapper implements the same standardized API while exposing model-specific capabilities and optimizations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}